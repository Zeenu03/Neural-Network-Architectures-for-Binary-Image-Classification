## **Subjective Questions**

### *Question 1: Are the results as expected? Why or why not?*
- The outcomes align with our expectations: VGG models with 1 and 3 blocks exhibit accuracies of 75% and 80% respectively. However, when data augmentation is applied to the VGG3 block model, its accuracy surpasses that of the standard VGG3 without such augmentation, reaching 87.5%. This improvement is attributed to the data augmentation technique, which artificially generates more data to enhance the model's learning capability.
- Transitioning to the VGG16 model, when all layers are trainable, it achieves an impressive accuracy of 92.5%. In contrast, the VGG16 model with only the final MLP layers trainable performs even better, achieving an accuracy of 95%. This discrepancy can be attributed to transfer learning: the latter model utilizes pre-trained weights from the ImageNet dataset, resulting in a more robust feature extractor compared to our dataset.
- Moreover, the model comprising only MLP layers, with parameters comparable to those of the VGG16 model, achieves an accuracy of 80%. This difference arises due to the inherent dissimilarities in how convolutional layers and MLP layers handle spatial information. While the convolutional layers in VGG16 act as local feature extractors, providing translational invariance to the model, MLP layers lack this property. Consequently, even minor shifts in the image can significantly impact the performance of the MLP model, whereas VGG16 remains more resilient to such variations.

### *Question 2: Does data augmentation help? Why or why not?*
- Yes, data augmentation does help. When data augmentation was applied to the VGG3 block model, its accuracy improved from 80% to 87.5%. This improvement underscores the effectiveness of data augmentation in enhancing model performance. Data augmentation is beneficial because it artificially creates more training data by applying random transformations to existing examples. This process diversifies the training dataset, enabling the model to learn more robust features and reducing overfitting. Consequently, the model becomes better equipped to generalize to unseen data, resulting in improved accuracy on the test set.

### *Question 3: Does it matter how many epochs you fine-tune the model? Why or why not?*
- Yes, the number of epochs does matter when fine-tuning a model. Each epoch allows the model to learn features from the images, potentially leading to improved classification accuracy. However, training for too many epochs can result in overfitting, where the model memorizes the training data and fails to generalize well to new data. Therefore, it's essential to strike a balance and choose an appropriate number of epochs to ensure the model effectively learns image features while also generalizing well.

### *Question 4: Are there any particular images that the model is confused about? Why or why not?*
- Yes, there are particular images that the model is confused about. This confusion arises when the features of the image are not clear, making it difficult even for humans to determine the correct class. For example, there is an image of a bear where all models except VGG16, trained only with MLP layers, predict it to be a Koala. Similarly, another image depicting a distant and blurry bear also leads to confusion among all models, which incorrectly classify it as a Koala. These instances highlight the challenges faced by the model when encountering ambiguous or unclear images.
